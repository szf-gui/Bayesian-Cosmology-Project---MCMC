{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Gh_f_7t2W67g"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_samples' from 'getdist' (C:\\Users\\GuilhermedeSouzaFern\\anaconda3\\Lib\\site-packages\\getdist\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Import GetDist for plotting and analysis\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Corrected: Import load_samples directly from getdist\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgetdist\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgetdist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plots, MCSamples, load_samples \n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# --- 1. Define Paths to Data and Likelihoods ---\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# IMPORTANT: This path is CRITICAL for Planck data.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# It should point to the directory containing the 'clik' data folders (e.g., Planck_highl_plik_R3.01, Commander_dx12_ell_min2_max29).\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# This is typically located in your user's home directory under '.cobaya/data/'.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Please verify this path on your system. If it's different, update it manually.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m cobaya_data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(Path\u001b[38;5;241m.\u001b[39mhome() \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.cobaya\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# This is the most common default Cobaya data path\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_samples' from 'getdist' (C:\\Users\\GuilhermedeSouzaFern\\anaconda3\\Lib\\site-packages\\getdist\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Jupyter Notebook: Combined Planck 2018 CMB + DESI BAO Analysis (ΛCDM)\n",
    "\n",
    "This notebook performs a combined cosmological parameter analysis using:\n",
    "1.  Planck 2018 Cosmic Microwave Background (CMB) data:\n",
    "    * High-multipole Temperature, E-mode Polarization, and Cross-polarization (TT, TE, EE) from Plik.\n",
    "    * Low-multipole E-mode Polarization (lowE).\n",
    "    * CMB Lensing reconstruction.\n",
    "2.  DESI (Dark Energy Spectroscopic Instrument) Baryon Acoustic Oscillation (BAO) data.\n",
    "\n",
    "The analysis is performed within the framework of the traditional 6-parameter ΛCDM model,\n",
    "using the Cobaya Bayesian analysis code and GetDist for results visualization.\n",
    "\"\"\"\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path # For more robust path handling\n",
    "\n",
    "# Ensure matplotlib plots are inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Import Cobaya for Bayesian analysis\n",
    "from cobaya.model import Model\n",
    "from cobaya.yaml import yaml_load_file\n",
    "from cobaya.run import run\n",
    "\n",
    "# Import GetDist for plotting and analysis\n",
    "# Corrected: Import load_samples directly from getdist\n",
    "import getdist\n",
    "from getdist import plots, MCSamples, load_samples \n",
    "\n",
    "# --- 1. Define Paths to Data and Likelihoods ---\n",
    "# IMPORTANT: This path is CRITICAL for Planck data.\n",
    "# It should point to the directory containing the 'clik' data folders (e.g., Planck_highl_plik_R3.01, Commander_dx12_ell_min2_max29).\n",
    "# This is typically located in your user's home directory under '.cobaya/data/'.\n",
    "# Please verify this path on your system. If it's different, update it manually.\n",
    "cobaya_data_path = str(Path.home() / \".cobaya\" / \"data\") # This is the most common default Cobaya data path\n",
    "\n",
    "print(f\"Assuming Cobaya data is located at: {cobaya_data_path}\")\n",
    "\n",
    "# Paths to Cobaya's core components (likely within your .venv)\n",
    "# These paths are usually correct if Cobaya itself is installed in the virtual environment.\n",
    "cobaya_base_path = os.path.join(os.getcwd(), '_packages', 'Lib', 'site-packages', 'cobaya')\n",
    "likelihoods_path = os.path.join(cobaya_base_path, 'likelihoods')\n",
    "theories_path = os.path.join(cobaya_base_path, 'theories')\n",
    "\n",
    "# Path to the Planck 2018 chains output directory\n",
    "planck_chains_output_dir = 'chains/planck_desi_lcdm_combined/'\n",
    "os.makedirs(planck_chains_output_dir, exist_ok=True) # Create output directory if it doesn't exist\n",
    "\n",
    "# --- File Existence Check ---\n",
    "print(\"\\n--- Verifying Required Data Files ---\")\n",
    "\n",
    "# Check Planck 2018 High-l Plik data\n",
    "# The 'data_path' parameter within the likelihood config is crucial for Cobaya to find the .clik_binary files.\n",
    "# The expected structure is cobaya_data_path / 'planck_2018_highl_plik' / 'Planck_highl_plik_R3.01'\n",
    "plik_clik_dir_name = 'planck_2018_highl_plik' # This is the module name in cobaya/likelihoods\n",
    "plik_data_actual_path = os.path.join(cobaya_data_path, plik_clik_dir_name, 'Planck_highl_plik_R3.01') # Specific clik data folder\n",
    "plik_exists = os.path.exists(plik_data_actual_path)\n",
    "print(f\"Planck 2018 High-l Plik data directory '{plik_data_actual_path}': {'EXISTS' if plik_exists else 'NOT FOUND'}\")\n",
    "if not plik_exists:\n",
    "    print(\"  (This is the actual *data* directory that the likelihood needs. If not found, run 'cobaya-install planck_2018_highl_plik')\")\n",
    "\n",
    "# Check Planck 2018 Low-l EE data\n",
    "lowl_clik_dir_name = 'planck_2018_lowl' # This is the module name\n",
    "lowl_data_actual_path = os.path.join(cobaya_data_path, lowl_clik_dir_name, 'Commander_dx12_ell_min2_max29.clik_binary') # Specific clik data file\n",
    "lowl_exists = os.path.exists(lowl_data_actual_path)\n",
    "print(f\"Planck 2018 Low-l EE data file '{lowl_data_actual_path}': {'EXISTS' if lowl_exists else 'NOT FOUND'}\")\n",
    "if not lowl_exists:\n",
    "    print(\"  (This is the actual *data* file that the likelihood needs. If not found, run 'cobaya-install planck_2018_lowl.EE')\")\n",
    "\n",
    "\n",
    "# Check Planck 2018 Lensing data\n",
    "lensing_clik_dir_name = 'planck_2018_lensing' # This is the module name\n",
    "lensing_data_actual_path = os.path.join(cobaya_data_path, lensing_clik_dir_name, 'PlanckLensing2018.clik_binary') # Specific clik data file\n",
    "lensing_exists = os.path.exists(lensing_data_actual_path)\n",
    "print(f\"Planck 2018 Lensing data file '{lensing_data_actual_path}': {'EXISTS' if lensing_exists else 'NOT FOUND'}\")\n",
    "if not lensing_exists:\n",
    "    print(\"  (This is the actual *data* file that the likelihood needs. If not found, run 'cobaya-install planck_2018_lensing')\")\n",
    "\n",
    "\n",
    "# Check DESI BAO data (relative to current working directory)\n",
    "desi_mean_file = os.path.join(os.getcwd(), 'bao_data-master', 'desi_2024_gaussian_bao_ALL_GCcomb_mean.txt')\n",
    "desi_cov_file = os.path.join(os.getcwd(), 'bao_data-master', 'desi_2024_gaussian_bao_ALL_GCcomb_cov.txt')\n",
    "\n",
    "desi_mean_exists = os.path.exists(desi_mean_file)\n",
    "desi_cov_exists = os.path.exists(desi_cov_file)\n",
    "\n",
    "print(f\"DESI BAO mean file '{desi_mean_file}': {'EXISTS' if desi_mean_exists else 'NOT FOUND'}\")\n",
    "print(f\"DESI BAO cov file '{desi_cov_file}': {'EXISTS' if desi_cov_exists else 'NOT FOUND'}\")\n",
    "if not (desi_mean_exists and desi_cov_exists):\n",
    "    print(\"  (DESI BAO data files not found. Ensure 'bao_data-master' is in your project root and contains these files.)\")\n",
    "\n",
    "print(\"--- File Verification Complete ---\")\n",
    "\n",
    "# --- 2. Configure the Cosmological Model and Likelihoods for Cobaya ---\n",
    "\n",
    "info = {\n",
    "    'params': {\n",
    "        'ombh2': {'prior': {'min': 0.019, 'max': 0.026}, 'ref': 0.0224, 'proposal': 0.00005, 'latex': r'\\Omega_{\\rm b}h^2'},\n",
    "        'omch2': {'prior': {'min': 0.09, 'max': 0.15}, 'ref': 0.120, 'proposal': 0.0005, 'latex': r'\\Omega_{\\rm c}h^2'},\n",
    "        'H0': {'prior': {'min': 40, 'max': 90}, 'ref': 67.4, 'proposal': 0.5, 'latex': r'H_0'},\n",
    "        'ns': {'prior': {'min': 0.92, 'max': 1.0}, 'ref': 0.965, 'proposal': 0.002, 'latex': 'n_s'},\n",
    "        'tau': {'prior': {'min': 0.03, 'max': 0.1}, 'ref': 0.054, 'proposal': 0.005, 'latex': r'\\tau'},\n",
    "        'logA': {'prior': {'min': 2.5, 'max': 3.5}, 'ref': 3.044, 'proposal': 0.002, 'latex': r'\\log(10^{10}A_s)'},\n",
    "        'As': {'value': 'lambda logA: 10**(logA)/1e10', 'latex': r'A_s'},\n",
    "        'sigma8': {'latex': r'\\sigma_8'},\n",
    "        'omegam': {'latex': r'\\Omega_m'},\n",
    "    },\n",
    "\n",
    "    'theory': {\n",
    "        'camb': {\n",
    "            'stop_at_error': False,\n",
    "            'path': os.path.join(theories_path, 'camb'),\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'likelihood': {\n",
    "        # Planck 2018 High-l (TT, TE, EE) Plik likelihood\n",
    "        # 'path' points to the Python wrapper. 'class' points to the class *within* that wrapper module.\n",
    "        # 'data_path' points to the actual clik data binaries.\n",
    "        'planck_2018_highl_plik': { \n",
    "            'path': os.path.join(likelihoods_path, 'planck_2018_highl_plik'),\n",
    "            'class': 'planck_2018_highl_plik.TTTEEE', # Explicit Python path to the class\n",
    "            'l_max_cached': 2508,\n",
    "            'data_path': plik_data_actual_path, # Use the path derived from cobaya_data_path\n",
    "        },\n",
    "        # Planck 2018 Low-l (EE) likelihood\n",
    "        'planck_2018_lowl_EE': { \n",
    "            'path': os.path.join(likelihoods_path, 'planck_2018_lowl'),\n",
    "            'class': 'planck_2018_lowl.EE', # Explicit Python path to the class\n",
    "            'data_file': lowl_data_actual_path, # Use the path derived from cobaya_data_path\n",
    "        },\n",
    "        # Planck 2018 Lensing likelihood\n",
    "        'planck_2018_lensing': {\n",
    "            'path': os.path.join(likelihoods_path, 'planck_2018_lensing'),\n",
    "            'class': 'planck_2018_lensing.clik', # Explicit Python path to the class\n",
    "            'data_path': lensing_data_actual_path, # Use the path derived from cobaya_data_path\n",
    "        },\n",
    "        # DESI BAO 2024 combined (ALL_GCcomb)\n",
    "        'desi_2024_bao_all': {\n",
    "            'path': os.path.join(likelihoods_path, 'bao'),\n",
    "            'data_file': desi_mean_file, # Use the path derived from os.getcwd()\n",
    "            'cov_file': desi_cov_file,   # Use the path derived from os.getcwd()\n",
    "        },\n",
    "    },\n",
    "\n",
    "    'sampler': {\n",
    "        'mcmc': {\n",
    "            'Rminus1_stop': 0.01,\n",
    "            'max_tries': 10000,\n",
    "            'learn_proposal': True,\n",
    "            'output_every': '60s',\n",
    "            'measure_speeds': True,\n",
    "            'oversample_power': 0.4,\n",
    "            'proposal_scale': 2,\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'output': planck_chains_output_dir + 'planck_desi_lcdm_output',\n",
    "    'debug': False\n",
    "}\n",
    "\n",
    "# --- 3. Run the Cobaya Sampler ---\n",
    "# This part will only run if the file checks above don't raise any issues.\n",
    "try:\n",
    "    print(\"\\nStarting Cobaya run for combined Planck + DESI ΛCDM analysis...\")\n",
    "    updated_info, products = run(info)\n",
    "    print(\"Cobaya run finished.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError during Cobaya run: {e}\")\n",
    "    print(\"Please resolve the file/path issues reported above before re-running.\")\n",
    "    # Exit or prevent further execution if the run failed\n",
    "    # In a notebook, 'raise' would stop execution. 'exit()' might stop the kernel.\n",
    "    # For now, we'll let it print the error and continue to the GetDist part\n",
    "    # but be aware that GetDist might fail if no chains were generated.\n",
    "\n",
    "\n",
    "# --- 4. Analyze and Plot Results using GetDist ---\n",
    "print(\"\\nAnalyzing results with GetDist...\")\n",
    "\n",
    "g = plots.get_subplot_plotter(width_inch=10)\n",
    "g.settings.title_limit = 1\n",
    "g.settings.alpha_filled_add = 0.8\n",
    "\n",
    "try:\n",
    "    # Load the generated chains\n",
    "    samples = load_samples(planck_chains_output_dir + 'planck_desi_lcdm_output')\n",
    "\n",
    "    plot_params = ['ombh2', 'omch2', 'H0', 'ns', 'tau', 'sigma8']\n",
    "\n",
    "    g.triangle_plot(samples, plot_params, filled=True, legend_loc='upper right')\n",
    "    g.export(planck_chains_output_dir + 'planck_desi_lcdm_triangle.png')\n",
    "    print(f\"Triangle plot saved to: {planck_chains_output_dir}planck_desi_lcdm_triangle.png\")\n",
    "\n",
    "    print(\"\\nMarginalized 1D Statistics:\")\n",
    "    for p in plot_params:\n",
    "        mean = samples.getMargeStats().pars[samples.index[p]].mean\n",
    "        std = samples.getMargeStats().pars[samples.index[p]].err\n",
    "        print(f\"{p}: {mean:.4f} +/- {std:.4f}\")\n",
    "\n",
    "    h0_limits = samples.getMargeStats().get_param_conf_limits('H0', alpha=0.32)\n",
    "    print(f\"\\nH0 (68% CL): {h0_limits.lower:.2f}, {h0_limits.upper:.2f} km/s/Mpc\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or plotting chains: {e}\")\n",
    "    print(\"Please check if the Cobaya run completed successfully and generated chain files.\")\n",
    "\n",
    "print(\"\\nAnalysis complete. Check the 'chains/planck_desi_lcdm_combined/' directory for output files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_samples' from 'getdist' (C:\\Users\\GuilhermedeSouzaFern\\anaconda3\\Lib\\site-packages\\getdist\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Import GetDist for plotting and analysis\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgetdist\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgetdist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plots, MCSamples, load_samples \n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# --- 1. Define Paths to Data and Likelihoods ---\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# IMPORTANT: This path is CRITICAL for Planck data.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# It should point to the directory containing the 'clik' data folders\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# BASED ON YOUR LAST ERROR, YOU LIKELY NEED TO USE THIS PATH:\u001b[39;00m\n\u001b[0;32m     37\u001b[0m cobaya_data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(Path\u001b[38;5;241m.\u001b[39mhome() \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.cobaya\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_samples' from 'getdist' (C:\\Users\\GuilhermedeSouzaFern\\anaconda3\\Lib\\site-packages\\getdist\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Jupyter Notebook: Simplified Planck 2018 High-l CMB Analysis (ΛCDM)\n",
    "\n",
    "This notebook performs a basic cosmological parameter analysis using:\n",
    "1.  Planck 2018 High-multipole Temperature, E-mode Polarization, and Cross-polarization (TT, TE, EE) from Plik.\n",
    "\n",
    "The analysis is performed within the framework of the traditional 6-parameter ΛCDM model,\n",
    "using the Cobaya Bayesian analysis code and GetDist for results visualization.\n",
    "\"\"\"\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path # For more robust path handling\n",
    "\n",
    "# Ensure matplotlib plots are inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Import Cobaya for Bayesian analysis\n",
    "from cobaya.model import Model\n",
    "from cobaya.yaml import yaml_load_file\n",
    "from cobaya.run import run\n",
    "\n",
    "# Import GetDist for plotting and analysis\n",
    "import getdist\n",
    "from getdist import plots, MCSamples, load_samples \n",
    "\n",
    "# --- 1. Define Paths to Data and Likelihoods ---\n",
    "# IMPORTANT: This path is CRITICAL for Planck data.\n",
    "# It should point to the directory containing the 'clik' data folders\n",
    "# (e.g., Planck_highl_plik_R3.01, Commander_dx12_ell_min2_max29, PlanckLensing2018.clik_binary).\n",
    "# This is typically located in your user's home directory under '.cobaya/data/'.\n",
    "#\n",
    "# BASED ON YOUR LAST ERROR, YOU LIKELY NEED TO USE THIS PATH:\n",
    "cobaya_data_path = str(Path.home() / \".cobaya\" / \"data\") \n",
    "print(f\"Assuming Cobaya data is located at: {cobaya_data_path}\")\n",
    "\n",
    "\n",
    "# Paths to Cobaya's core components (likely within your .venv)\n",
    "cobaya_base_path = os.path.join(os.getcwd(), '_packages', 'Lib', 'site-packages', 'cobaya')\n",
    "likelihoods_path = os.path.join(cobaya_base_path, 'likelihoods')\n",
    "theories_path = os.path.join(cobaya_base_path, 'theories')\n",
    "\n",
    "# Path to the chains output directory\n",
    "planck_chains_output_dir = 'chains/planck_highl_lcdm_simplified/'\n",
    "os.makedirs(planck_chains_output_dir, exist_ok=True) # Create output directory if it doesn't exist\n",
    "\n",
    "# --- File Existence Check ---\n",
    "print(\"\\n--- Verifying Required Data Files ---\")\n",
    "\n",
    "# Check Planck 2018 High-l Plik data\n",
    "plik_clik_dir_name = 'planck_2018_highl_plik' \n",
    "# The specific folder name containing the .clik_binary files for plik is usually 'Planck_highl_plik_R3.01'\n",
    "plik_data_actual_path = os.path.join(cobaya_data_path, plik_clik_dir_name, 'Planck_highl_plik_R3.01') \n",
    "plik_exists = os.path.exists(plik_data_actual_path)\n",
    "print(f\"Planck 2018 High-l Plik data directory '{plik_data_actual_path}': {'EXISTS' if plik_exists else 'NOT FOUND'}\")\n",
    "if not plik_exists:\n",
    "    print(\"  (CRITICAL: This directory must exist and contain the Planck high-l data.)\")\n",
    "    print(f\"  If not found, try running in your terminal/Anaconda Prompt: 'cobaya-install {plik_clik_dir_name}'\")\n",
    "    print(f\"  OR manually specify the correct 'cobaya_data_path' in this notebook.\")\n",
    "\n",
    "print(\"--- File Verification Complete ---\")\n",
    "\n",
    "# --- 2. Configure the Cosmological Model and Likelihoods for Cobaya ---\n",
    "\n",
    "info = {\n",
    "    'params': {\n",
    "        'ombh2': {'prior': {'min': 0.019, 'max': 0.026}, 'ref': 0.0224, 'proposal': 0.00005, 'latex': r'\\Omega_{\\rm b}h^2'},\n",
    "        'omch2': {'prior': {'min': 0.09, 'max': 0.15}, 'ref': 0.120, 'proposal': 0.0005, 'latex': r'\\Omega_{\\rm c}h^2'},\n",
    "        'H0': {'prior': {'min': 40, 'max': 90}, 'ref': 67.4, 'proposal': 0.5, 'latex': r'H_0'},\n",
    "        'ns': {'prior': {'min': 0.92, 'max': 1.0}, 'ref': 0.965, 'proposal': 0.002, 'latex': 'n_s'},\n",
    "        'tau': {'prior': {'min': 0.03, 'max': 0.1}, 'ref': 0.054, 'proposal': 0.005, 'latex': r'\\tau'},\n",
    "        'logA': {'prior': {'min': 2.5, 'max': 3.5}, 'ref': 3.044, 'proposal': 0.002, 'latex': r'\\log(10^{10}A_s)'},\n",
    "        'As': {'value': 'lambda logA: 10**(logA)/1e10', 'latex': r'A_s'},\n",
    "        'sigma8': {'latex': r'\\sigma_8'},\n",
    "        'omegam': {'latex': r'\\Omega_m'},\n",
    "    },\n",
    "\n",
    "    'theory': {\n",
    "        'camb': {\n",
    "            'stop_at_error': False,\n",
    "            'path': os.path.join(theories_path, 'camb'),\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'likelihood': {\n",
    "        # Only Planck 2018 High-l (TT, TE, EE) Plik for now\n",
    "        'planck_2018_highl_plik': { \n",
    "            'path': os.path.join(likelihoods_path, 'planck_2018_highl_plik'),\n",
    "            'class': 'planck_2018_highl_plik.TTTEEE',\n",
    "            'l_max_cached': 2508,\n",
    "            'data_path': plik_data_actual_path, # Use the path derived from cobaya_data_path\n",
    "        },\n",
    "    },\n",
    "\n",
    "    'sampler': {\n",
    "        'mcmc': {\n",
    "            'Rminus1_stop': 0.01,\n",
    "            'max_tries': 10000,\n",
    "            'learn_proposal': True,\n",
    "            'output_every': '60s',\n",
    "            'measure_speeds': True,\n",
    "            'oversample_power': 0.4,\n",
    "            'proposal_scale': 2,\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'output': planck_chains_output_dir + 'planck_highl_lcdm_output',\n",
    "    'debug': False\n",
    "}\n",
    "\n",
    "# --- 3. Run the Cobaya Sampler ---\n",
    "# This part will only run if the file checks above don't raise any issues.\n",
    "run_successful = False\n",
    "if plik_exists: # Only attempt run if the primary data file is found\n",
    "    try:\n",
    "        print(\"\\nStarting Cobaya run for simplified Planck High-l ΛCDM analysis...\")\n",
    "        updated_info, products = run(info)\n",
    "        print(\"Cobaya run finished.\")\n",
    "        run_successful = True\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during Cobaya run: {e}\")\n",
    "        print(\"Please resolve the file/path issues reported above before re-running.\")\n",
    "else:\n",
    "    print(\"\\nSkipping Cobaya run due to missing Planck data files.\")\n",
    "\n",
    "\n",
    "# --- 4. Analyze and Plot Results using GetDist ---\n",
    "print(\"\\nAnalyzing results with GetDist...\")\n",
    "\n",
    "g = plots.get_subplot_plotter(width_inch=10)\n",
    "g.settings.title_limit = 1\n",
    "g.settings.alpha_filled_add = 0.8\n",
    "\n",
    "if run_successful:\n",
    "    try:\n",
    "        # Load the generated chains\n",
    "        samples = load_samples(planck_chains_output_dir + 'planck_highl_lcdm_output')\n",
    "\n",
    "        plot_params = ['ombh2', 'omch2', 'H0', 'ns', 'tau', 'sigma8']\n",
    "\n",
    "        g.triangle_plot(samples, plot_params, filled=True, legend_loc='upper right')\n",
    "        g.export(planck_chains_output_dir + 'planck_highl_lcdm_triangle.png')\n",
    "        print(f\"Triangle plot saved to: {planck_chains_output_dir}planck_highl_lcdm_triangle.png\")\n",
    "\n",
    "        print(\"\\nMarginalized 1D Statistics:\")\n",
    "        for p in plot_params:\n",
    "            mean = samples.getMargeStats().pars[samples.index[p]].mean\n",
    "            std = samples.getMargeStats().pars[samples.index[p]].err\n",
    "            print(f\"{p}: {mean:.4f} +/- {std:.4f}\")\n",
    "\n",
    "        h0_limits = samples.getMargeStats().get_param_conf_limits('H0', alpha=0.32)\n",
    "        print(f\"\\nH0 (68% CL): {h0_limits.lower:.2f}, {h0_limits.upper:.2f} km/s/Mpc\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or plotting chains: {e}\")\n",
    "        print(\"Please check if the Cobaya run completed successfully and generated chain files.\")\n",
    "else:\n",
    "    print(\"\\nSkipping GetDist analysis as Cobaya run was not successful.\")\n",
    "\n",
    "print(\"\\nAnalysis complete. Check the 'chains/planck_highl_lcdm_simplified/' directory for output files (if run was successful).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
